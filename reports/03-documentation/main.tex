\RequirePackage[svgnames]{xcolor}

\documentclass[a4paper,english,10pt,NET]{tumarticle}

% TUM packages
\usepackage{tumfonts}
\usepackage{tumarticle}
\usepackage{tumlocale}
\usepackage{tumcmd}

\usepackage{graphicx}
\usepackage[style=american]{csquotes}
\usepackage{hyperref}
\usepackage{xspace}

\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{pdflscape}

\usepackage{siunitx}
\usepackage{todo}

\usepackage{cleveref}

\usepackage{tikz}
\usepackage{messagepassing}
\ifdefined\oobcolor\oobcolor{gray}\fi
\ifdefined\oobcolour\oobcolour{gray}\fi

\usepackage{bytefield}
\usetikzlibrary{arrows.meta,calc,fit,positioning,decorations.pathmorphing,automata,shapes}
\tikzset{
	>={Stealth[scale=0.7]},
	every edge/.style={>={Stealth[scale=0.7]},draw,},
	automata/.style={
		->,
		every edge/.style={>={Stealth[scale=1.3]},font=\footnotesize,shorten >=1pt,draw,},
		font=\small,
		initial text={},
		every state/.style={draw=TUMBlue,very thick,fill=TUMLightBlue,ellipse,},
		every loop/.style={looseness=5,},
		node distance=1.8cm and 2.3cm,
	},
}

% TODO main -> gossip
% was renamed when adding the testing binary and the reorganization in this step
\input{listingsSetup}

\definecolor{Type}{HTML}{FF7700}
\definecolor{Interface}{HTML}{B4A7E5}
\colorlet{Struct}{Aquamarine}
\NewDocumentCommand{\PumlCircle}{mm}{\tikz[baseline=(n.base)]\node[inner sep=0.07em,circle,fill=#1,draw=black] (n) {\texttt{#2}};}

\renewcommand{\eg}{\mbox{e.\,g.}\xspace} % already defined in tumcmd but without xspace
\renewcommand{\ie}{\mbox{i.\,e.}\xspace} % already defined in tumcmd but without xspace
\newcommand{\cf}{\mbox{c.\,f.}\xspace}
\newcommand{\tos}{$\to$\xspace}

% default for positioning floats
\makeatletter
\renewcommand*{\fps@figure}{htp}
\renewcommand*{\fps@table}{htp}
\makeatother

% Set document title. If no language is supplied, the document language is
% assumed.
\title{P2Psec Project -- Documentation}
\author{Fabio Gaiba, Lukas Heindl}
\date{September 9th, 2024}

\begin{document}

\maketitle
\thispagestyle{tumarticle}

\section{Introduction}
This document will introduce the overall design of our module \textbf{Whisper2Peer}.
First, we will describe how our application is built, tested, and run.
Then, we will show the module architecture logically and the different threads used in the process.
Since we are using golang, we implement threads by using goroutines.
Note that we use the terms \emph{goroutine} and \emph{thread} interchangeably for simplicity.
We will give sample scenarios to understand how messages are processed and travel the program.
We will also show our abstractions over the networking layer.

% TODO(pull) change needed if pull is implemented
After that, we will cover the concrete gossip strategy we implemented, including the different parameters used in the strategy.
Later, we will discuss the security measure we implemented and the peer-to-peer protocol we put in place.
Finally, we will explore what next steps would make sense when continuing to work on this project and how the workload was distributed between the team members.

\section{How to run/build}
The application is written in golang.
Therefore, the tools provided by golang can (and should) be used to build and test the application.
You will find more information on this aspect in our \texttt{README.md}\footnote{\url{https://gitlab.lrz.de/netintum/teaching/p2psec_projects_2024/Gossip-3/-/blob/main/gossip/README.md}}.
\Todo{does this automatically install the dependencies?}

If you need\,/\,want a more technical documentation for every function\,/\,struct defined, you can make use of the documentation generated by the \texttt{godoc} tool\footnote{\url{https://pkg.go.dev/golang.org/x/tools/cmd/godoc}}.
For this, run \lstinline{godoc -http=:6060} in the \texttt{gossip/} folder and navigate to \url{http://localhost:6060/pkg/gossip/} in the Web-Browser.

\section{Module Architecture}
We decided to divide the project into four main packages.
Those main packages are described in \cref{fig:overview}.
The following is just a brief overview.
Each part will be discussed in more detail in the following subsections.

\begin{itemize}
	\item \textbf{Gossip}:
		is in charge of managing the whole module.
		It has to take and use the configuration parameters, orchestrate the other components, and filter and relay messages.
		Moreover, in this package, we define the data structure that holds the registered \textit{Gossip Types} in memory.
	\item \textbf{Vertical API}:
		its main goal is to manage the connections to other modules.
		It provides an abstraction over the networking part and manages the marshaling and un-marshaling of the messages under the hood.
	\item \textbf{Horizontal API}:
		is very similar to the \texttt{Vertical API}, except it has to communicate with the peer's Gossip modules.
	\item \textbf{Gossip-Strategy}:
		this package is in charge of instantiating a concrete strategy for disseminating the information between peers.
		It leverages the \texttt{Horizontal API} to communicate with peers, focusing just on how to handle the messages.
\end{itemize}

In addition to these four main packages, there is also a \textbf{Common} package, holding common data types, an internal \textbf{Ringbuffer} package, defining a circular queue data structure used to store data to be spread in the network and a \textbf{PoW} package implementing (parallelized) solving of proof-of-work challenges.

Those modules create threads that communicate with message passing, as seen again in \cref{fig:overview}. This design decision allows the program to be highly scalable due to the degree of parallelization.

\begin{figure}
	\centering
	\input{figures/overview}
	\caption{A high level overview of the modules and the channels.}
	\label{fig:overview}
\end{figure}

\subsection{Logical structure}
Using UML class diagrams is the standard way of modeling the logical structure of a project (at least with object orientation).
It quickly shows how classes are connected\,/\,coupled to each other, and what data a class stores.

The UML class diagram for the packages of our project can be seen in \cref{fig:classDia}.
The \PumlCircle{Struct}{S} marks a struct/class,
the \PumlCircle{Interface}{I} marks interfaces, and
the \PumlCircle{Type}{T} marks a type.
Types (as marked with \PumlCircle{Type}{T}) usually are simple type aliases for an existing class (or a built-in type of golang).
Note that for a better overview, this diagram is primarily structured like \cref{fig:overview} with the vertical API on the left and the horizontal API on the right.
Also, the diagram is already complex enough with just the classes for the application itself.
Thus, we refrained from adding some classes only used for (end-to-end) testing (and benchmarking).
For more information on that part of our project, please refer to \cref{sec:testing}.

In our case, most communication is not done by function calls but by message passing.
Thus, fewer functions are defined on our classes than expected, and the present ones are more general, like \lstinline{Listen} or \lstinline{Run}.
To gain a deeper understanding of the internal communication, please refer to \cref{sec:msgpassing}.
Still, getting a rough overview of what class implements which interface is also useful for the message passing. \label{sumtypes}
For message passing, we need to focus on the interfaces starting with \texttt{To*} and \texttt{From*}.
As sum-types\,/\,unions are not natively supported by golang, our workaround is to send objects implementing the respective interface on each channel.
When receiving on such a channel, we can safely \texttt{switch} over the object's type and handle the respective message.
We use the tool \emph{go-sumtype}\footnote{\url{https://github.com/BurntSushi/go-sumtype}} to check if the \texttt{switch} statements handle all cases needed (actually, this only works in a specific scenario, but for more on this refer to the documentation of that tool).

In \cref{sec:structureNetworking}, we will go into more detail regarding the networking part.
For now, it is only important that while we implement de- and serialization on the vertical API ourselves, we use capnproto\footnote{\url{https://github.com/capnproto/go-capnp}} on the horizontal API for this task.
The respective logic in both cases is contained in the respective \texttt{types} subpackage.
Since the capnproto code is generated automatically (and contains some capnproto internals), we omit the \texttt{horizontalAPI/types} package while including the \texttt{verticalAPI/types} package in the diagram.

Also, note that golang does not have the concept of constructors for a class.
Therefore, data needed\,/\,used for initialization of the classes is not visible in the class diagram.
In most cases, the constructor is pretty straightforward.
The \texttt{strategy} package is an exception to this.
Here, there is only one generic constructor \texttt{New}, which returns an object that implements the \texttt{StrategyCloser} interface (at the moment, this is only the \texttt{dummyStrat}).
If one would implement a second strategy, this generic constructor would decide which strategy to use based on the arguments.

One additional special case might be the \texttt{common} package.
First, this was contained in the \texttt{verticalAPI/types} package, but as we progressed, we figured it would be a good idea to extract the definition of some message types we use throughout the whole module.
This way, we avoid the necessity to include the \texttt{verticalAPI/types} package everywhere.
During further development, a few additional definitions were added to this package with the same reasoning.

Also, a bit confusing at first sight might be the \texttt{internal/packetcounter} package.
This is used to collect statistics and for (end-to-end) testing (and benchmarking).

Note: The way we split the application into modules, you can also think of the modules (shown in \cref{fig:overview}) as layers.
In this view, the layers from the bottom up would be \texttt{horizontalAPI}, \texttt{strategy}, \texttt{gossip}, \texttt{verticalAPI}.

\begin{landscape}
	\pagestyle{empty}
	\begin{figure}
		\centering
		\hspace*{-0.1\linewidth}\includegraphics[width=1.2\linewidth]{figures/class}
		\caption{Class diagram for the packages included in our project, generated by PlantUML.}
		\label{fig:classDia}
	\end{figure}
\end{landscape}

\subsection{Process architecture} \label{sec:msgpassing}

To explain the current process architecture, we opted to first give a general overview of how the processes are spawned and supposed to communicate through channels. Secondly, we will display a few scenarios to show how the threads communicate with each other.

\subsubsection{Processes (threads) Creation} \label{process-creation}

\texttt{Gossip} is the entry point of the whole module. This thread spawns a listener \texttt{Vertical API} thread that keeps accepting new connection to the module from other modules following the specification of the problem statement. For each new connection, two new routines are spawned: one that receives and processes messages and one that sends messages. Communication directed to or from routines created by \texttt{Vertical API} happens respectively with channels of the \texttt{ToVert} and \texttt{FromVert} types.

Then, \texttt{Gossip} creates the \texttt{Strategy} thread, which then spawns a listener thread for the \texttt{Horizontal API}. The latter, similarly to the \texttt{Vertical API}, accepts new connection and creates for each one two threads, one for reading and one for writing. Communication between \texttt{Gossip} and \texttt{Strategy} routines happens via the \texttt{FromStrat} and \texttt{ToStrat} channels, while \texttt{Strategy} communicates with threads of \texttt{Horizontal API} via the \texttt{FromHz} and \texttt{ToHz} channels.

As already mentioned, there is actually no communication between \texttt{Horizontal API} goroutines and the \texttt{Gossip}. The channels used for communication can be seen on the arrows in \cref{fig:overview}. It is important to note that there will actually be multiple channels directed to the \textit{Vertical API} (\texttt{ToVert}), as well as multiple channels directed to the \textit{Horizontal API} (\texttt{ToHz}). This is because incoming messages from the network are aggregated on the same channel while outgoing messages are sent to specific hosts, so different channels.


\subsubsection{Scenario 1: Gossip Notify Message}

The first scenario we want to display is the reception of a Gossip Notify message. For the sake of clarity, a single Vertical API thread is used to show both the writing and reading threads.

In this case the message passing is trivial (see \cref{fig:msg-notify}). The Vertical API (\texttt{vertAPI}) receives the \textit{Gossip Notify} message (\texttt{notify}), marshals it and sends it to the main (\texttt{main}) thread where the Gossip Type is registered. It is interesting to note that what we store is the writing communication channel. As previously mentioned in \cref{process-creation}, there are multiple writing channels, one for each host. This greatly simplifies the sending procedure.

\begin{figure}
	\centering
	\input{figures/msgpass-notify}
	\caption{Message passing when a Gossip Notify message is received}
	\label{fig:msg-notify}
\end{figure}

\subsubsection{Scenario 2: Gossip Announce Message}

In this scenario, a Gossip Announce message is sent to the Vertical API (\texttt{vertAPI}) thread. This message (\texttt{ann}) goes to the Main (\texttt{main}) module which verifies that the type is registered and if so forwards the message to the Strategy (\texttt{strat}). The strategy then sends the message to the Horizontal API (\texttt{hzAPI}) which takes care of actually sending the message to other peers. In the form of a \textit{PUSH} message. 

The delay in the Strategy, from reception to sending, is due to the implementation. Messages are sent in rounds, so they need to wait until a new sending round starts.

\begin{figure}
	\centering
	\input{figures/msgpass-announce}
	\caption{Gossip Announce message is received}
	\label{fig:msg-announce}
\end{figure}


\subsubsection{Scenario 3: Peer Relayed a Message}

In this last scenario, we depict the handling of a peer \textit{PUSH} message \cref{fig:msg-relay}. First, the message is received by the Horizontal API (\texttt{hzAPI}), then it goes to the concrete Strategy (\texttt{strat}). The strategy processes the message accordingly and asks main (\texttt{main}) to perform a Gossip Notification for such message (\texttt{notific}). If such Gossip Type is registered, Main instructs the Vertical API (\texttt{vertAPI}) to send to connected modules such message (\texttt{notific}). After that, the Vertical API receives a Gossip Validation message (\texttt{val}). On reception, this message travels the threads back to the strategy, which if the message is valid begins to spread it itself. In the figure this is the \textit{PUSH} message marked in gray. If the original message was not deemed valid, the message is not spread further.

\begin{figure}
	\centering
	\input{figures/msgpass-relay}
	\caption{Peer receive \textit{PUSH} message}
	\label{fig:msg-relay}
\end{figure}


\subsection{Networking} \label{sec:structureNetworking}
For networking, we first need to differentiate between the two APIs in our module.
First, the vertical API, and second, the horizontal API.

\subsubsection{vertical API}
On the vertical API, we communicate with other modules typically running on the same peer.
At this point, these modules are implemented by someone else (\eg another team from the lecture).
Therefore, we were handed a specification that defines the format of the messages on that API.
With the hard requirement to adhere to this specification, we can't use capnproto at this point, so we need to implement the de-\,/\,parsing on our own.
If you look back at the class diagram in \cref{fig:classDia} again, this is implemented in the \texttt{verticalAPI/types} package.

\subsubsection{horizontal API}
On the other side, we have the horizontal API, which is only used for our module to communicate with the same module running on another peer.
As a result, we are completely free to come up with a custom message format on this API.
For reference on the types used, please refer to \cref{sec:msgtypes}.
In our case, we decided to use capnproto as a library that does the de-\,/\,parsing for us.
Analog to the vertical API, the code generated by capnproto is placed in the \texttt{horizontalAPI/types} package.

\subsubsection{both API-modules}
Apart from the difference in the message formats and the de-\,/\,parsing the horizontal API and the vertical API modules are quite similar.
Both modules use two threads, one for reading from and one for writing to the socket, per connection, in addition to the one thread used to establish (and dispatch) new connections.
Thereby, they both provide a layer of abstraction on top of the raw TCP sockets where other threads can send a message on the respective golang channel and (try to) receive from the golang channel in the other direction.

Especially for reading, having the golang channel is nice since we can use golang's built-in \texttt{select} statement when waiting for messages on multiple sockets.
This approach is not strictly necessary for writing.
Still, having a dedicated thread and the golang channel for communication allows us to send the message to the API module and continue execution without waiting until the message is sent on the network connection.

In general, this architecture also allows us to have multiple listening (read) and multiple writing threads connected to the API module.
We have not implemented multiple listening threads since we did not need it so far.
Also note how this use of one thread per read\,/\,write on the connection combined with the communication via golang channels implicitly synchronizes the write operations (although in golang, this is not strictly necessary to be done manually).


\section{Gossip Strategies}
\Todo{text here how to instantiate different ones and what the idea here is (also with the main/root strategy as kind of library)}
\Todo{3 caches (of size cache size messages) and state machine should be a common scheme}

The spreading of information in the network is done by the Gossip Strategy module. Since the actual way of spreading the messages could be done in many different ways (strategies), we decided to split the logic between a \textbf{Main Strategy} and a \textbf{Concrete Strategy}. There is also a class \textbf{Connection Manager} which has the task of managing the connection to the peers. 

The Main Strategy is the base component common to any Concrete Strategy. It instantiates the horizontalAPI, creates the Connection Manager object and finally the Concrete Strategy. On the other hand, a Concrete Strategy  has the job of processing incoming messages and sending its own. The whole sake of this separation is providing modularity. Our implementation offers just one strategy, the Push Strategy, but having the redundant code extracted in a common Base Class would ease in the implementation of a new strategy. That is the reason of having a Main Strategy and a Connection Manager.


\subsection{Connection Manager}

The first aspect which is in common to any Strategy is the Connection Manager. This class is responsible for abstracting the management of connections and providing a clean interface for them. This is needed due to our security measures (\cref{sec:security}), as connections have to be validated through Proofs of Work regularly. As a result, the connection state may change (e.g., a connection can become valid or invalid). These changes might occur concurrently, which could easily lead to an invalid state.

Therefore, we decided to allow changes to the internal state of connections only through a carefully exposed interface. Some of the functionalities of the Connection Manager are finding a connection for a gived ConnectionID, removing a connection or making a connection valid upon receiving a PoW.

\subsection{Gossip Messages}

\begin{figure}
	\centering
	\input{figures/fsm_msgs}
	\caption{Finite state machine for message caching.}
	\label{fig:fsm_msgs}
\end{figure}

Ultimately, the Gossip Strategy has to receive messages, notify the verticalAPI and forward them to other peers. By specification, a received message has to be validated before it is spread to other peers. After being sent to \textit{Degree} peers, there is no need to keep sending the message. We decided to use 3 states to describe this behavior, as described in \cref{fig:fsm_msgs}: 

\begin{itemize}
	\item \textbf{Invalid Messages}: messages that were received, but still needs validation
	\item \textbf{Valid Messages}: messages that were validated and are now being spread in the network
	\item \textbf{Sent Messages}: messages that were sent to \textit{Degree} peers 
\end{itemize}

Those states are held in a \textbf{Ringbuffer}, a circular queue data structure which make it very easy discarding the oldest messages when enough (\textit{cache\_size}) messages are stored. 

\subsection{Push Strategy}
The push strategy is straight forward.
Every peer pushes new updates to a random subset of its neighbors.

\begin{minipage}{0.50\linewidth}
	\begin{lstlisting}[
		language=pseudo,
		morekeywords={[3]{main,hz}},
		morekeywords={[4]{msg,degree,cache\_size}},
		caption={Pseudo code of the push gossip strategy}
	]
		on push from hz(msg):
			if msg is new (unseen) (not in any of the three caches):
				emit a notification to the main module
				mark msg as invalid for now

		on announce from main(msg):
			append msg to valid messages

		on validation from main(msg):
			if ttl == 1:
				move msg from invalid messages to sent messages
			else:
				move msg from invalid messages to valid messages

		on gossip round():
			S = random subset of the neighbors of size degree
			send all valid messages to S
			if a message was sent more than degree times:
				move msg from valid to sent messages
	\end{lstlisting}
\end{minipage}

When a message is received, it becomes invalid (stays in the invalid queue) unless it was already present in cache (in that case, it is immediately dropped). Such message is sent to the main module, which will interact with the \texttt{Vertical API} for notifying the client. If a \texttt{GOSSIP VALIDATION} message arrives, this means that a recently received message (now stored in the Invalid Queue) can be moved to the Valid Queue and can start to be sent to neighbors. If \texttt{ttl} was one, instead of being relayed to other peers the message is put in the Sent Queue, as there is no need to further spread the information. Messages received through a \texttt{GOSSIP ANNOUNCE} are automatically deemed Valid.

\texttt{Gossip Rounds} are triggered periodically. When the Gossip Round starts, a random subset of peers of size \textit{Degree} is chosen (via a random permutation). Then, each message in the Valid Queue is sent to each chosen peer. Every stored message has a counter, which is increased by one everytime it is sent. Once the counter reach \textit{cache\_size} neighbors, the message is moved to the Sent Queue.


\section{Security Measures} \label{sec:security}



\Todo{describe how PoW works (what fields are included) -- also how to adjust and make the challenge harder -- also parallelization}

From a security perspective, the Gossip module is mainly susceptible to \textit{Sybil Attacks} and consequently \textit{Eclipse Attacks}. This is because, when running, a peer is accepting any new connection and there is no central authority which can help with verifying the identity of other entities. To provide Identity Validation we opted for a computation based Proof of Work. This way we limit the amount of Identities which can be under the control of an attacker to the computational resources that such attacker has. 

\subsection{Identity Validation}

The act of validating identity in our system involves solving a Proof of Work (PoW) challenge. Specifically, this means finding a nonce (a random or pseudo-random value) that, when appended to a given challenge, results in a hash output with a specified number ($n$) of leading zeros. This process is similar to the one of the registration challenge.

The purpose of this PoW mechanism is to ensure that the client has invested computational effort in proving its legitimacy. Once the correct nonce is identified and appended to the challenge, any peer can verify such PoW efficiently: if the hash function generates an output that starts with the required number of leading zeros, the Proof of Work is considered valid.

This mechanism provides security by making it computationally expensive to forge identities or spam the system with invalid connections (\textit{Sybil Attacks}). 

The difficulty of the challenge, controlled by the number of leading zeros $n$ required in the hash, can be adjusted based on the desired level of security. Higher numbers of leading zeros require more computational work, making the system more secure but also more resource-intensive. But the difficulty can also be raised by putting a (small) time constrain for the computation of such PoW.

In our project, $n$ is set to 8 bits, meaning the hash must start with 8 leading zeros. However, the optimal security parameters can only be determined by running the nodes in a real test environment. Various combinations of timeout lengths and the number of leading zeros may be suitable, depending on the specific circumstances.

\subsection{PoW Protocol Design}

The Proof of Work happens through the exchange of Horizontal messages. To explain how we designed the Identity Validation protocol, let's go through an example. Peer $A$ is up, and peer $B$ is instructed to connect to peer $A$:

\begin{enumerate}
	\item $B \to A$ send a request. The message only purpose is to instruct $A$ of creating and providing a challenge
	\item $A \to B$ send a challenge. 
	\item $B \to A$ send the Proof of Work. If valid, the Identity is validated
\end{enumerate}


\subsubsection{Connection Types}

To better model the PoW, we decided upon 3 possible connection state:

\begin{enumerate}
	\item \texttt{To Be Proved Connections}: peers to which a PoW needs to be sent
	\item \texttt{In Progress Connections}: peers which need to send us a PoW
	\item \texttt{Open Connections}: peers that were validated (or we validated us against)
\end{enumerate}

These states become handy when receiving and handling PoW messages, as we must verify that a message is coming from a connection in a specific state. For example, we only accept Challenges if the connection is a To Be Proved ones. Or we automatically drop PUSH messages if the connection is not a valid one (not present in the Open Connections).

\subsubsection{Proof of Work methods}

\Todo{Describe how we compute the pow, with parallelization and the magic trick}

\subsubsection{Cookies}

\begin{table}
	\centering
	\input{figures/cookie}
	\caption{Cookies content}
	\label{tab:cookie}
\end{table}

When a peer is validating incoming connection, some information should be maintained. This can let an attacker opening a lot of connection, leave them half done (not providing the PoW) and increasing the memory load on the peer much like a TCP SYN Flood attack. To avoid keeping a state in memory, the sent challenge contains a cookie. 

The cookie content is shown in \cref{tab:cookie}. It is composed of the Ip and Port of the peer which needs to ba validated, a timestamp of when the cookie was created and a Nonce, used by the encryption algorithm. The cookie is then encrypted using ChaCha20-Poly1305 \footnote{\url{https://en.wikipedia.org/wiki/ChaCha20-Poly1305}} and the nonce is also appended as plaintext. The used key is randomly generated at startup by the peer.

Upon reception of the PoW, the Cookie is decrypted and the content is inspected to check the validity. For example the timestamp should not be larger then a certain timeout value.

\subsection{Periodical Proofs of Work}

The PoW requires an attacker to put computational effort when opening a connection. But if this is done only once, the attacker con use the resource sequentially, adding Sybils to its control over time. To avoid this, we implemented Periodic Proofs of Work: a node periodically asks the neighboring peers for a PoW and at the same time the node will be prompted by each of its neighbors for PoWs. 

We have previously thought about aggregating the received Challenges into a single PoW so that a node does not waste too many resources into multiple PoW. Otherwise we would penalize nodes that have many connections. At the same time, by aggregating, an attacker could open as many connection as he wants paying the same computational cost. In the end, we opted for providing PoW for each connection. This as an higher load on the peers but provide the best security against Sybils.

The Periodic PoW is specular to the previously illustrated ones. There are two timers, one for requesting challenges to all Open Connections (valid ones) and one for closing connection which did not provide the Periodic PoW. The former must be shorter than the latter (at least half) as there is no synchronization between peers.  

\section{Specification of the peer-to-peer protocol} \label{sec:msgtypes}
This module works with two protocols, one on the vertical API and one on the horizontal API.
The one for the vertical API was already predetermined.
Its specification can be found in the \emph{specification.pdf} document (see moodle\footnote{\url{https://www.moodle.tum.de/mod/resource/view.php?id=3090766}}).
For the other one, we had the freedom to develop something independently.
To avoid writing the de-\,/\,parsing ourselves, we chose to use capnproto.
Capnproto is a data serialization format that comes with libraries in multiple different languages and a respective code generator for those languages.
With capnproto, you only specify what data (\enquote{name} and type) should be in the message.
The concrete message format is then the concern of capnproto.

With this in mind, it makes no real sense to include the concrete format of the messages but only the names of the fields and their type.
% TODO(pull)
As of now, we have seven message types on the horizontal API.
The most important one is the \emph{Push} message type, which is used to spread information in the network.
Its fields and types can be seen in \cref{tab:push}.

The six remaining message types can be split into two groups, one with the \emph{Conn} prefix and one with the \emph{Pow} prefix.
Both groups are of size three.
Regarding the payload, both sets of message types are equal.
We use different message types nonetheless since we use them in a slightly different context and want to be able to differentiate what message exactly was sent.
Both sets of message types consist of
a \emph{Req} message type (see \cref{tab:req}),
a \emph{Chall} message type (see \cref{tab:chall}) and
a \emph{Pow} message type (see \cref{tab:pow}).
All of them are used for our security mechanism.
For more information on this mechanism, please refer to \cref{sec:security}.

The actual message sent on the horizontal API is not a raw instance of the message described above but a more generic message type, which is a simple union of all message types that can be sent on the horizontal API.
This approach makes it possible to add more message types as we go by simply adding more types to this union.
The nice thing at this point is that capnproto handles the complete checking of which message type was sent (resolving the union, so to speak).
This way, we do not need to come up with, \eg a messageType field on our own and allocate identifiers for the individual types.

\begin{table}
	\centering
	\input{figures/hzMsgs_push}
	\caption{
		Contents of a \texttt{Push} message.
		Used to spread information.
	}
	\label{tab:push}
\end{table}

\begin{table}
	\centering
	\input{figures/hzMsgs_req}
	\caption{
		Contents of a \texttt{\{Conn,Pow\}Req}* message.
		Used for the security mechanism.
	}
	\label{tab:req}
\end{table}

\begin{table}
	\centering
	\input{figures/hzMsgs_chall}
	\caption{
		Contents of a \texttt{\{Conn,Pow\}Chall} message.
		Used for the security mechanism.
	}
	\label{tab:chall}
\end{table}

\begin{table}
	\centering
	\input{figures/hzMsgs_pow}
	\caption{
		Contents of a \texttt{\{Conn,Pow\}PoW}* message.
		Used for the security mechanism.
	}
	\label{tab:pow}
\end{table}

\section{Testing} \label{sec:testing}
Testing can be split into multiple categories.
In this project, we make use of unit testing and end-to-end testing.
Both kinds of tests are written in files suffixed with \texttt{\_test.go}.
Therefore, if you use \lstinline{go test} to run the tests, both kinds of tests are executed.

You will find the files containing the unit tests placed side-by-side the files containing the code they test.
Unit testing is straightforward and will not be covered in more detail in this documentation.

For the end-to-end testing, we came up with a more complex setup that relies on a \texttt{Tester} class (see \texttt{internal/testutils/}) for the most part.
You will find the specification of the test cases in \texttt{gossip/main/main\_test.go}.
But now let us focus on the \texttt{Tester} class used in the process.

The basic idea for end-to-end testing is to bring up multiple instances of our application, one for each node in a network.
The topology of the network is defined beforehand in a JSON file.
Afterward, we can instruct one instance to spread information in the network, and we can observe how the nodes in the network handle this.

In order to do so, we create multiple goroutines, one for each node, and launch our application with the respective configuration in each of these goroutines.
To observe the process, we set up each instance to output its logs in JSON format and output log statements with a predefined log level (only used for this kind of testing).
We can then parse the redirected JSON log output in the testing routine and collect it for later use.
Additionally, for each node, we open a TCP connection for the vertical API to control the node, just like in a real-world scenario.

All this functionality is implemented in the \texttt{Tester} class.
\texttt{NewTesterFromJSON} parses the JSON file defining the topology,
\texttt{Startup} starts the application multiple times and opens the vertical API connections, and
\texttt{Teardown} closes all the connections and terminates all instances.
Having all these functionalities collected in one class has the advantage that we can use it for multiple different test cases.

For ease of use, we added more functions to the \texttt{Tester} class.
One example is registering a certain \emph{gossipType} on all nodes so that all nodes participate in spreading the information.
Another example is waiting until no more messages are sent (for a particular duration) on the horizontal connections (except for PoW messages).
The latter is particularly useful when waiting until the information was spread before calling \texttt{Teardown}.

Writing all this in golang has the advantage of simply reusing the struct definitions of our project.
This is particularly useful when sending messages on the vertical API.
Also, this makes integrating the tests in the golang way of running tests easier.

The goal was to provide a layer of abstraction on top of the whole management of the nodes so that the actual test case is just a simple playbook of what should happen.
Therefore, if you look at the end-to-end tests, they read very script-like.

The \texttt{Tester} was also designed to be used for some benchmarks.
In this case, the approach of using a predefined log level comes in handy as it allows the placement of various hooks in the codebase, which can later be used during benchmarking.
We already started looking at, \eg which node receives the information when and how many packets are sent at which point in time.
For this reason, you will already find some code regarding analyzing of the gathered data in the \texttt{Tester} class.
However, as randomness is involved in the gossip strategy, coming up with good metrics is quite challenging.
This is why, in the end, we did not perform extended benchmarking, providing us with results we can present at this point.

\section{Future Work} \label{sec:future}
\Todo{outdated!!}
\Todo{pull strategy?}
\Todo{benchmaring (stubs are present)?}
We already built a decent architecture which allows us to easily add new components or replace existing ones.
We plan on adding at least a pull strategy, whether we still have time for a push-pull strategy remains unclear.

Additionally, we plan to also add some end-to-end tests on a simple network for which we can determine which peers should receive the message being spread.
Having an infrastructure for this end-to-end testing should also make it possible to do some sort of benchmarking with much larger networks.
For this we plan on generate some networks in advance (using the models presented in the lecture which are implemented in the python library networkx\footnote{\url{https://networkx.org/}}).
We can then use these predefined networks to setup the peers and spread one (or multiple) messages in the network.
Based on the logging we can then evaluate which peer received which message at what point in time.
Here it comes to our advantage that everything runs on the same host which implies the clocks are perfectly in sync.
This benchmarking approach should allow us to perform some comparisons at least with different parameters, or if we implemented an additional strategy also compare the different strategies.

For now we do not have the security mesaures presented in \cref{sec:security} in place.
We plan to implement at least the discussed proof-of-work based security measure until the end of the project.

\section{Workload distribution}
As already outlined, we split our module in various different packages.
This enabled us to distribute the packages and work independently of each other (apart from defining the communication\,/\,interface of course).

Fabio focused on the developing the Strategy package, which was greatly written in peer programming, especially in the beginning when defining the whole interface. He also wrote the tests for the vertical API and developed the most part of the PoW security mechanism.

Lukas worked on the horizontal API and the vertical API (from which the common package later was derived).
Note that at least writing the de-\,/\,parsing of the vertical API was pretty straight forward because it is fairly similar to what we needed to do for the registration client.
He also wrote the module which is used to solve the PoW challenge (in parallel) and developed the capabilities for easy end-to-end testing (and the stubs for benchmarking).

While Fabio started working on the main package, Lukas later did some refactoring and finalized the package.

\section{Effort spent for the project}
Both of us did not strictly measure the time spent on the project. We report here a rough estimation on weekly hours spent working on the project, since the creation and submission of the initial report.

\begin{itemize}
	\item Fabio: 8-9 hours a week
	\item Lukas: 9-10 hours a week
\end{itemize}

We would also like to stress that this estimation is an average.
There were weeks where one member did slightly less and weeks when he did more.
Moreover, it is not the case that those hours were spread equally across the week, but rather done in 3-4 hours long session (in a few occasion a bit more).
Also, sometimes these were pair-programming sessions or sessions for planning where the architecture was planned (and almost no code was written).
Especially after the lecture period ended Fabio was able to put more effort into the project while Lukas worked more on the project arround the exam phase.

\todos

\end{document}
